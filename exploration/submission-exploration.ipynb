{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the most reccomeneded books on Reddit\n",
    "\n",
    "People often use Amazon links (to books) in Reddit comments to act as a proxy for what books are being mentioned the most on Reddit. This is due to the fact that Amazon links are easy to parse (see regex) and look up (see Amazon PA-API). However, this isn't necessarily an accurate proxy, as there are countless mentions to books by just using the title and author (e.g. *The Intelligent Investor by Benjamin Graham*).\n",
    "\n",
    "Many of these book mentions come from submissions asking questionss such as these:\n",
    "* [Reddit, what are some \"MUST read\" books?](https://www.reddit.com/r/AskReddit/comments/34m5n6/reddit_what_are_some_must_read_books/)\n",
    "* [What are /r/investing's favorite books? - Future side bar link.](https://www.reddit.com/r/investing/comments/166ha8/what_are_rinvestings_favorite_books_future_side/)\n",
    "* [What is a good cook book for a beginner?](https://www.reddit.com/r/Cooking/comments/6m5enh/what_is_a_good_cook_book_for_a_beginner/)\n",
    "\n",
    "Taking a brief look at these posts, there are almost no Amazon links, and consequently modern scrapers will not pick up these book reccomendations. Even more, these posts are highly targeted, and garner attention from the entire community--often providing hundreds of book reccomendations with in-depth discussions for each one. To miss out on these would be very detrimental to a reccomendation service that strives to be accurate.\n",
    "\n",
    "**Our goal in this notebook is to find a reliable method capable of finding which books were mentioned in a comment.** Here are some observations that may lead to such an algortihm:\n",
    "- Books are almost always mentioned in the top-level comments (in the kind of submissions mentioned above)\n",
    "- Most people capitalize the book title\n",
    "- Most people mention the author\n",
    "    - e.g. The Intelligent Investor **by Benjamin Graham**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base imports\n",
    "import praw\n",
    "import requests\n",
    "import time\n",
    "from urllib.error import HTTPError, URLError\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting some sample comments to work with\n",
    "In order to first build and test our parser, we will gather sample comments from two subreddits that are dedicated soley to suggseting books:\n",
    "* [r/SuggestMeABook](https://reddit.com/r/suggestmeabook)\n",
    "* [r/booksuggestions](https://reddit.com/r/booksuggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reddit_client():\n",
    "    api_creds = {}\n",
    "    with open('../puller-api-creds.env') as f:\n",
    "        for line in f:\n",
    "            k, v = line.rstrip().split('=')\n",
    "            api_creds[k] = v\n",
    "    return praw.Reddit( user_agent='book submission parser',\n",
    "                        client_id=api_creds['CLIENT_ID'],\n",
    "                        client_secret=api_creds['CLIENT_SECRET'],\n",
    "                        username=api_creds['USERNAME'],\n",
    "                        password=api_creds['PASSWORD'] )\n",
    "\n",
    "\n",
    "def sub_exists(reddit, subreddit):\n",
    "    from prawcore import NotFound\n",
    "    exists = True\n",
    "    try:\n",
    "        reddit.subreddits.search_by_name(subreddit, exact=True)\n",
    "    except NotFound:\n",
    "        exists = False\n",
    "    return exists\n",
    "\n",
    "\n",
    "def get_subreddit_sample_comments(reddit, subreddit_name):\n",
    "    \"\"\" \n",
    "    Retrieves top level comments from `subreddit_names` top submissions this wee\n",
    "    \"\"\"\n",
    "    if not sub_exists(reddit, subreddit_name):\n",
    "        raise ValueError(\"please enter a valid subreddit name\")\n",
    "    comments = []\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    for submission in subreddit.top(time_filter='week'):\n",
    "        comments.extend(submission.comments)\n",
    "        break\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the client\n",
    "reddit = get_reddit_client()\n",
    "# gather some arbritrary sample comments\n",
    "comments = get_subreddit_sample_comments(reddit, 'booksuggestions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered 38 sample comments\n",
      "--------------------------------------------------------------------------------\n",
      "I got into Hitch Hiker's Guide to the Galaxy around that age, it's a really fun read and I think mostly appropriate. \n",
      "\n",
      "Ready Player One is a great book if he liked Ender's Game, the movie is coming out soon so be sure he gets the book first!\n",
      "--------------------------------------------------------------------------------\n",
      "Isaac Asimov's Foundation series or his robot series, although I believe there may be some adult themes. That said, I don't think they were particularly graphic, one of the criticisms of Asimov (at least according to wikipedia) is that he did not really address sexuality at all. \n",
      "--------------------------------------------------------------------------------\n",
      "What you are looking for is called \"hard science fiction\", with a \"young adult\" sub-genre. See [here](https://bookriot.com/2018/01/02/hard-science-fiction/) and [here](https://best-sci-fi-books.com/23-best-hard-science-fiction-books/) for more background and book recommendations.  \n",
      "  \n",
      "Among Heinlein's material, I think these are suitable.  \n",
      "Starman Jones  \n",
      "Have Space Suit, Will Travel  \n",
      "Citizen of the Galaxy  \n",
      "  \n",
      "The Honor Harrington (David Weber) series should fit well too.  \n",
      "As well as Apocalypse Troll, The Excaliber Alternative. 1633 is kinda reverse sci-fi, a modern American small town is transported back to 1633 Europe and tries to survive.  \n",
      "  \n",
      "A Fire Upon the Deep was good.  \n",
      "  \n",
      "I think March Upcountry and series was age appropriate, but its hard to remember (John Ringo has a deserved salty reputation).   \n",
      "  \n",
      "Also check out youtube channel [Isaac Arthur](https://www.youtube.com/channel/UCZFipeZtQM5CKUjx6grh54g). This channel is in-depth discussions about potential technology and futurism from a realistic perspective, and explores sci-fi tropes and assumptions. \n"
     ]
    }
   ],
   "source": [
    "print(f'Gathered {len(comments)} sample comments')\n",
    "for comment in comments[:3]:\n",
    "    print('-' * 80)\n",
    "    print(comment.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a preliminary parsing pipeline\n",
    "The stages of parsing book titles out of a comment will be broken into the following steps:\n",
    "\n",
    "**Important Note**: Comments on Reddit are represented by markdown\n",
    "\n",
    "1. Get the text-representation of the rendered markdown \n",
    "2. Tokenize the comment text into sentences\n",
    "3. Tokenize each sentence into words\n",
    "4. Find consecutive sequences of capitalized non-stopword words\n",
    "    * e.g. I thought that *The Intelligent Investor: The Definitive Book on Value Investing* was a great book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from markdown import markdown\n",
    "\n",
    "DEBUG = False\n",
    "# Really abritrary title length requirement\n",
    "MIN_TITLE_LEN = 3\n",
    "# Global stopwords set (for quick lookup)\n",
    "STOPWORDS = set(stopwords.words())\n",
    "\n",
    "def markdown_to_text(md):\n",
    "    html = markdown(md)\n",
    "    return ''.join(BeautifulSoup(html, 'lxml').findAll(text=True))\n",
    "\n",
    "\n",
    "def _trim_trailing_stopwords(words):\n",
    "    while words and words[-1] in STOPWORDS:\n",
    "        words.pop()\n",
    "    return words\n",
    "\n",
    "\n",
    "def _match_titles(sentence):\n",
    "    \"\"\"\n",
    "    Return title(s) found in a sentence, where a title is defined as:\n",
    "        a consecutive sequence of capitalized non-stopword words\n",
    "    \"\"\"\n",
    "    titles = []\n",
    "    seq = [] \n",
    "    # filter out the special chars, e.g. ''', '\"', ',', etc.\n",
    "    words = filter(lambda w: w.isalnum(), word_tokenize(sentence))\n",
    "    for word in words:\n",
    "        # title 'ends' on a non-stopword non-capitalized word\n",
    "        if seq and word not in STOPWORDS and not word[0].isupper():\n",
    "            titles.append(seq[:])\n",
    "            seq = []\n",
    "        elif seq and word in STOPWORDS:\n",
    "            seq.append(word)\n",
    "        elif word[0].isupper():\n",
    "            seq.append(word)    \n",
    "    titles.append(seq)\n",
    "    trimmed = map(_trim_trailing_stopwords, titles)\n",
    "    filtered = filter(lambda l: len(l) >= MIN_TITLE_LEN, trimmed)\n",
    "    return [' '.join(title) for title in filtered if title]\n",
    "        \n",
    "\n",
    "def extract_titles_from_comment(comment):\n",
    "    \"\"\" \n",
    "    Extracts all book titles found in a comment body\n",
    "    See the pipeline steps mentioned in the cell above.\n",
    "    \"\"\"\n",
    "    titles = set()\n",
    "    # avoid dealing with all the special markup characters\n",
    "    text = markdown_to_text(comment.body)\n",
    "    # for each sentence, extract the title(s)\n",
    "    for sentence in sent_tokenize(text):\n",
    "        \n",
    "        titles_found = _match_titles(sentence)\n",
    "        if DEBUG:\n",
    "            print(f'sentence: {sentence}')\n",
    "            print('titles found:')\n",
    "            print(\"\\n\".join(titles_found))\n",
    "            print('-' * 80)\n",
    "        titles.update(titles_found)\n",
    "    return titles\n",
    "\n",
    "\n",
    "def bulk_extract(comments):\n",
    "    \"\"\" \"\"\"\n",
    "    all_titles = set()\n",
    "    for comment in comments:\n",
    "        titles = extract_titles_from_comment(comment)\n",
    "        all_titles.update(titles)\n",
    "    return list(all_titles)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vatta s War',\n",
       " 'Ready Player One',\n",
       " 'The Transall Saga and I',\n",
       " 'A Fire Upon the Deep',\n",
       " 'The Stories of Your Life',\n",
       " 'We Are Are Bob',\n",
       " 'Old Man War by John Scalzi Another',\n",
       " 'Wrinkle in Time',\n",
       " 'Captain s Kid by Liz Coley',\n",
       " 'Check out the We Are Legion We Are Bob',\n",
       " 'Heinlein Asimov Ray Bradbury David Weber s Honor Harrington Wrinkle in Time Leviathan and John Scalzi and Ready Player One',\n",
       " 'Redshirts by John Scalzi',\n",
       " 'The Lost Fleet',\n",
       " 'We Are Legion We Are Bob by Dennis E Taylor A',\n",
       " 'Asimov or Clarke',\n",
       " 'Elizabeth Moon and the YA',\n",
       " 'We Are Legion We Are Bob',\n",
       " 'Dragon Egg by Robert Forward and Children of Time by Adrian Tchaikovsky Both',\n",
       " 'Apocalypse Troll The Excaliber Alternative',\n",
       " 'Mortal Engines by Phillip Reeve',\n",
       " 'Farmer in the Sky by Heinlein',\n",
       " 'Check these out Ancillary Justice by Ann Leckie',\n",
       " 'The Hitchhiker Guide to the Galaxy by Douglas Adams',\n",
       " 'Hitch Hiker Guide to the Galaxy',\n",
       " 'Citizen of the Galaxy by Heinlein',\n",
       " 'The Golden Compass by Philip Pullman',\n",
       " 'Ringworld by Larry Niven',\n",
       " 'Childhood s End by Arthur Clark The Martian Chronicles by Ray Bradbury',\n",
       " 'Time Travel to Multiple Universes',\n",
       " 'Jurassic Park I',\n",
       " 'Children of Time',\n",
       " 'The Tomorrow Code by Brian Falkner',\n",
       " 'Isaac Asimov Foundation',\n",
       " 'Lock In by Scalzi',\n",
       " 'Starman Jones Have Space Suit Will Travel Citizen of the Galaxy The Honor Harrington David Weber',\n",
       " 'A Space Odyssey by Arthur C Clarke A',\n",
       " 'Anathem by Neal Stephenson Touted',\n",
       " 'Congo and Sphere']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_extracted_titles = bulk_extract(comments)\n",
    "sample_extracted_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leveraging the Google books API to get book metadata from just the title\n",
    "Using Google's API provides the simplest method, however there is a cap at 1000 requests per day, so it must be used sparingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_BOOKS_API_URL = 'https://www.googleapis.com/books/v1/volumes'\n",
    "\n",
    "def google_book_search(title):\n",
    "    \"\"\" https://developers.google.com/books/docs/v1/using#PerformingSearch \"\"\"\n",
    "    params = {\n",
    "        'q': title,\n",
    "        'key': 'AIzaSyAgwbY2ojVCKMnnxoua7QJ0aYiYJxePmcQ',\n",
    "        'maxResults': 1,\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(GOOGLE_BOOKS_API_URL, params=params).json()\n",
    "        if 'items' not in resp:\n",
    "            print(f'no google search results found for title: {title}')\n",
    "            resp = None  # nothing really to work with when 0 items returend\n",
    "        return resp\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "        return\n",
    "\n",
    "def google_metadata_from_title(title):\n",
    "    \"\"\"\n",
    "    Get the most relevant search result from Google books API and returns a dict of metadata:\n",
    "    {'isbn': <isbn>, 'title': <title>}\n",
    "    \"\"\"\n",
    "    resp = google_book_search(title)\n",
    "    if not resp:\n",
    "        return\n",
    "    try:\n",
    "        metadata = resp['items'][0]['volumeInfo']\n",
    "        ids = metadata['industryIdentifiers']  # isbn10, isbn13, etc.\n",
    "        \n",
    "        return {\n",
    "            'isbn': next(d['identifier'] for d in ids if d['type'] == 'ISBN_10'), \n",
    "            'title': metadata['title'],\n",
    "            'authors': metadata['authors']\n",
    "        }\n",
    "    except StopIteration:\n",
    "        print(f'incompatible google search result format for title: {title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Google API results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted title: The Laws of Nature by Ashley Franz Holzmann\n",
      "Matched title: The Laws of Nature by Ashley Franz Holzmann\n",
      "--------------------------------------------------------------------------------\n",
      "Extracted title: The Surgeon Tess Gerritsen\n",
      "Matched title: The Surgeon by Tess Gerritsen\n",
      "--------------------------------------------------------------------------------\n",
      "Extracted title: Blood Meridian by Cormac McCarthy\n",
      "Matched title: Blood Meridian by Cormac McCarthy\n",
      "--------------------------------------------------------------------------------\n",
      "Extracted title: Flowers In The Attic VC Andrews\n",
      "Matched title: Flowers In The Attic by V.C. Andrews\n",
      "--------------------------------------------------------------------------------\n",
      "Extracted title: The Tsar of Love and Techno by Anthony Marra\n",
      "Matched title: The Tsar of Love and Techno by Anthony Marra\n",
      "--------------------------------------------------------------------------------\n",
      "Extracted title: Eleven Twenty Three by Jason Hornsby Preta Realm by J Thorn A\n",
      "Matched title: The Cult of the Amateur by Andrew Keen\n",
      "--------------------------------------------------------------------------------\n",
      "Extracted title: Also Lull by Kelly Link\n",
      "Matched title: Magic for Beginners by Kelly Link\n",
      "--------------------------------------------------------------------------------\n",
      "Extracted title: Twenty Days of Turin The Water Knife\n",
      "Matched title: Hunters & Collectors by M. Suddain\n",
      "--------------------------------------------------------------------------------\n",
      "Extracted title: The Stuff of Nightmares by Malorie Blackman\n",
      "Matched title: The Stuff of Nightmares by Malorie Blackman\n",
      "--------------------------------------------------------------------------------\n",
      "Extracted title: Slade House by David Mitchell\n",
      "Matched title: Slade House by David Mitchell\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "google_results = []\n",
    "for title in sample_extracted_titles[:10]:\n",
    "    print(f'Extracted title: {title}')\n",
    "    result = google_metadata_from_title(title)\n",
    "    google_results.append(result if result else {})\n",
    "    if not result:\n",
    "        continue\n",
    "    print(f'Matched title: {result[\"title\"]} by {\", \".join(result[\"authors\"])}')\n",
    "    print('-' * 80)\n",
    "    time.sleep(.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leveraging the Goodread's API to get book metadata from just the title\n",
    "The goodreads API is slightly more involved, as title searches only returns Goodreads internal book id, which you must then translate to an ISBN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOODREADS_SEARCH_API_URL = 'https://www.goodreads.com/search/index.xml'\n",
    "def goodreads_title_search(title):\n",
    "    \"\"\" https://www.goodreads.com/api/index#search.books \"\"\"\n",
    "    params = {\n",
    "        'q': title,\n",
    "        'key': 'CZ44l5tAA26Dp2hGQywKg',\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(GOODREADS_SEARCH_API_URL, params=params)\n",
    "        xml = BeautifulSoup(resp.text, 'xml')\n",
    "        if not xml.find('results') or not xml.find('results').find('work'):\n",
    "            xml = None  # no results is essnetially useless\n",
    "        return xml\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "\n",
    "GOODREADS_SHOW_API_URL = 'https://www.goodreads.com/book/show'\n",
    "def goodreads_show_by_id(book_id):\n",
    "    \"\"\" \n",
    "    https://www.goodreads.com/api/index#book.show \n",
    "    Lookup book reviews and metadata by goodread's interal book id\n",
    "    \"\"\"\n",
    "    endpoint = f'{book_id}.xml'  # they use a very weird endpoint format\n",
    "    params = {\n",
    "        'key': 'CZ44l5tAA26Dp2hGQywKg'\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(f'{GOODREADS_SHOW_API_URL}/{endpoint}', params=params)\n",
    "        xml = BeautifulSoup(resp.text, 'xml')\n",
    "        if not xml.find('book'):\n",
    "            xml = None\n",
    "        return xml\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "    \n",
    "def goodreads_id_from_title(title):\n",
    "    \"\"\"  \"\"\"\n",
    "    resp = goodreads_title_search(title)\n",
    "    if not resp:\n",
    "        print(f'no goodreads book search results returned for title: {title}')\n",
    "        return\n",
    "    try:\n",
    "        work = resp.find('results').find('work')\n",
    "        if work.find('best_book_id'):\n",
    "            return work.find('best_book_id').text\n",
    "        else:\n",
    "            return work.find('best_book').find('id').text\n",
    "    except AttributeError:\n",
    "        print(f'incomplete goodreads book API response for title: {title}')\n",
    "        return\n",
    "    \n",
    "\n",
    "def goodreads_isbn_from_id(book_id):\n",
    "    resp = goodreads_show_by_id(book_id)\n",
    "    if not resp:\n",
    "        print(f'no goodreads books returned for goodreads book id: {book_id}')\n",
    "        return\n",
    "    try:\n",
    "        isbn = resp.find('isbn').text\n",
    "        if ' ' in isbn:\n",
    "            return None\n",
    "        return isbn\n",
    "    except AttributeError as e:\n",
    "        print(f'no isbn contained in response for goodreads book id: {book_id}')\n",
    "        \n",
    "\n",
    "def goodreads_isbn_from_title(title):\n",
    "    goodreads_id = goodreads_id_from_title(title)\n",
    "    if not goodreads_id:\n",
    "        return\n",
    "    isbn = goodreads_isbn_from_id(goodreads_id)\n",
    "    return isbn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing problems and possible soltuions\n",
    "* **Problem**: The markdown to text operation removes newlines, which are often use to break up titles\n",
    "    * We can split the comment body by '\\n', resulting in paragraphs, which we can then run the parsing pipeline on\n",
    "* **Problem**: Comments may mention many books, separated by commas, which the current pipeline cannot handle\n",
    "    * The solution to this is just to ignore it, a bad solution, but there is no easy fix for this since many titles contain commas\n",
    "* **Problem**: People often separate *title* and *author* by special characters which the current parsing pipeline removes\n",
    "    * No solution yet\n",
    "* **Problem**: If the commenter mentions the book title multiple times in the comment, first with the author and then without it, the parser will pick up both as separate instances. \n",
    "    * The solution to this must is to map both mentions to the same book, where we can then identify the duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved version, implementing the solutions to the problems stated above\n",
    "def extract_titles_from_comment(comment):\n",
    "    \"\"\" \n",
    "    Extracts all book titles found in a comment body\n",
    "    \"\"\"\n",
    "    titles = set()\n",
    "    whole_text = markdown_to_text(comment.body)\n",
    "    # avoid dealing with all the special markup characters\n",
    "    for paragraph in comment.body.split('\\n'):\n",
    "        text = markdown_to_text(paragraph)\n",
    "        # for each sentence, extract the title(s)\n",
    "        for sentence in sent_tokenize(text):\n",
    "            titles_found = _match_titles(sentence)\n",
    "            titles.update(titles_found)\n",
    "    return titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_extracted_titles2 = bulk_extract(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titles that our improved algorithm picked up that the original didn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ancillary Justice by Ann Leckie',\n",
       " 'Childhood s End by Arthur Clark',\n",
       " 'Children of Time by Adrian Tchaikovsky',\n",
       " 'Citizen of the Galaxy',\n",
       " 'Dragon Egg by Robert Forward',\n",
       " 'Have Space Suit Will Travel',\n",
       " 'The Honor Harrington David Weber',\n",
       " 'The Martian Chronicles by Ray Bradbury'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sample_extracted_titles2) - set(sample_extracted_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating parsed titles\n",
    "Here we take the titles we parsed out and search the Google Books API for them. The API will retrieve the most relevant title, which we can then evaluate (using a diffing algortihm). If the match is high enough, we can assume that the parsed title is referencing that book, gather the metadata from the API response (ISBN, author, title, year published, etc.), and move forward.\n",
    "\n",
    "The main goal here is to **develop an algorithm that can tell whether our parsed title and the API response title are referencing the same thing**. Here are some things that we'll have to deal with:\n",
    "* Many of our parsed titles include the author, whereas the API title won't (since author is in a separate field of the API response)\n",
    "* Our parsed titles may include typos due to user error\n",
    "* Our parsed titles often only include what we call the *main-title*, whereas the API response title contains the *main-title* and the *sub-title*.\n",
    "\n",
    "    ```\n",
    "           Main title                 Subtitle\n",
    "    v-----------------------v v--------------------------v\n",
    "    The Intelligent Investor: A Book of Practical Counsel:\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_referencing_the_same(parsed_title, api_title):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
