{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the most reccomeneded books on Reddit\n",
    "\n",
    "People often use Amazon links (to books) in Reddit comments to act as a proxy for what books are being mentioned the most on Reddit. This is due to the fact that Amazon links are easy to parse (see regex) and look up (see Amazon PA-API). However, this isn't necessarily an accurate proxy, as there are countless mentions to books by just using the title and author (e.g. *The Intelligent Investor by Benjamin Graham*).\n",
    "\n",
    "Many of these book mentions come from submissions asking questionss such as these:\n",
    "* [Reddit, what are some \"MUST read\" books?](https://www.reddit.com/r/AskReddit/comments/34m5n6/reddit_what_are_some_must_read_books/)\n",
    "* [What are /r/investing's favorite books? - Future side bar link.](https://www.reddit.com/r/investing/comments/166ha8/what_are_rinvestings_favorite_books_future_side/)\n",
    "* [What is a good cook book for a beginner?](https://www.reddit.com/r/Cooking/comments/6m5enh/what_is_a_good_cook_book_for_a_beginner/)\n",
    "\n",
    "Taking a brief look at these posts, there are almost no Amazon links, and consequently modern scrapers will not pick up these book reccomendations. Even more, these posts are highly targeted, and garner attention from the entire community--often providing hundreds of book reccomendations with in-depth discussions for each one. To miss out on these would be very detrimental to a reccomendation service that strives to be accurate.\n",
    "\n",
    "**Our goal in this notebook is to find a reliable method capable of finding which books were mentioned in a comment.** Here are some observations that may lead to such an algortihm:\n",
    "- Books are almost always mentioned in the top-level comments (in the kind of submissions mentioned above)\n",
    "- Most people capitalize the book title\n",
    "- Most people mention the author\n",
    "    - e.g. The Intelligent Investor **by Benjamin Graham**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base imports\n",
    "import praw\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting some sample comments to work with\n",
    "In order to first build and test our parser, we will gather sample comments from two subreddits that are dedicated soley to suggseting books:\n",
    "* [r/SuggestMeABook](https://reddit.com/r/suggestmeabook)\n",
    "* [r/booksuggestions](https://reddit.com/r/booksuggestions)\n",
    "\n",
    "We will futher refine our sample by only gathering comments from submissions that are asking a question (i.e. the title ends with a '?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reddit_client():\n",
    "    api_creds = {}\n",
    "    with open('../puller-api-creds.env') as f:\n",
    "        for line in f:\n",
    "            k, v = line.rstrip().split('=')\n",
    "            api_creds[k] = v\n",
    "    return praw.Reddit( user_agent='book submission parser',\n",
    "                        client_id=api_creds['CLIENT_ID'],\n",
    "                        client_secret=api_creds['CLIENT_SECRET'],\n",
    "                        username=api_creds['USERNAME'],\n",
    "                        password=api_creds['PASSWORD'] )\n",
    "\n",
    "\n",
    "def sub_exists(reddit, subreddit):\n",
    "    from prawcore import NotFound\n",
    "    exists = True\n",
    "    try:\n",
    "        reddit.subreddits.search_by_name(subreddit, exact=True)\n",
    "    except NotFound:\n",
    "        exists = False\n",
    "    return exists\n",
    "\n",
    "\n",
    "def get_subreddit_sample_comments(reddit, subreddit_name):\n",
    "    if not sub_exists(reddit, subreddit_name):\n",
    "        raise ValueError(\"please enter a valid subreddit name\")\n",
    "    comments = []\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    for submission in subreddit.top(time_filter='week'):\n",
    "        if submission.title[-1] != '?':\n",
    "            continue\n",
    "        comments.extend(submission.comments)\n",
    "        break\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the client\n",
    "reddit = get_reddit_client()\n",
    "# gather some arbritrary sample comments\n",
    "comments = get_subreddit_sample_comments(reddit, 'suggestmeabook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered 68 sample comments\n",
      "--------------------------------------------------------------------------------\n",
      "*The Painted Bird* by Kozinski should make you lose faith in humanity.\n",
      "--------------------------------------------------------------------------------\n",
      "The Collector by John Fowles\n",
      "\n",
      "It was unsettling how 'normal' the characters thoughts and actions became as you kept reading \n",
      "--------------------------------------------------------------------------------\n",
      "The Conspiracy Against The Human Race by Thomas Ligotti. I swear to god this book is dangerous, I read it for the first time when I was already in a really nihilistic, existentially distraught place and it pretty much confirmed and enforced the way I was feeling. I am still and always will be a big Ligotti fan but I do wonder if the last 5 years would have been different if I didnâ€™t go into such a downward spiral at such a crucial time in my life.\n"
     ]
    }
   ],
   "source": [
    "print(f'Gathered {len(comments)} sample comments')\n",
    "for comment in comments[:3]:\n",
    "    print('-' * 80)\n",
    "    print(comment.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a preliminary parsing pipeline\n",
    "The stages of parsing book titles out of a comment will be broken into the following steps:\n",
    "\n",
    "**Important Note**: Comments on Reddit are represented by markdown\n",
    "\n",
    "1. Get the text-representation of the rendered markdown \n",
    "2. Tokenize the comment text into sentences\n",
    "3. Tokenize each sentence into words\n",
    "4. Find consecutive sequences of capitalized non-stopword words\n",
    "    * e.g. I thought that *The Intelligent Investor: The Definitive Book on Value Investing* was a great book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from markdown import markdown\n",
    "\n",
    "DEBUG = False\n",
    "# Really abritrary title length requirement\n",
    "MIN_TITLE_LEN = 4\n",
    "# Global stopwords set (for quick lookup)\n",
    "STOPWORDS = set(stopwords.words())\n",
    "\n",
    "def markdown_to_text(md):\n",
    "    html = markdown(md)\n",
    "    return ''.join(BeautifulSoup(html, 'lxml').findAll(text=True))\n",
    "\n",
    "\n",
    "def _trim_trailing_stopwords(words):\n",
    "    while words and words[-1] in STOPWORDS:\n",
    "        words.pop()\n",
    "    return words\n",
    "\n",
    "\n",
    "def _match_titles(sentence):\n",
    "    \"\"\"\n",
    "    Return title(s) found in a sentence, where a title is defined as:\n",
    "        a consecutive sequence of capitalized non-stopword words\n",
    "    \"\"\"\n",
    "    titles, seq = [], []\n",
    "    # filter out the special chars, e.g. ''', '\"', ',', etc.\n",
    "    words = filter(lambda w: w.isalnum(), word_tokenize(sentence))\n",
    "    for word in words:\n",
    "        # title 'ends' on a non-stopword non-capitalized word\n",
    "        if seq and word not in STOPWORDS and not word[0].isupper():\n",
    "            titles.append(seq[:])\n",
    "            seq = []\n",
    "        elif seq and word in STOPWORDS:\n",
    "            seq.append(word)\n",
    "        elif word[0].isupper():\n",
    "            seq.append(word)\n",
    "            \n",
    "    titles.append(seq)\n",
    "    trimmed = map(_trim_trailing_stopwords, titles)\n",
    "    filtered = filter(lambda l: len(l) >= MIN_TITLE_LEN, trimmed)\n",
    "    return [' '.join(title) for title in filtered if title]\n",
    "        \n",
    "\n",
    "def extract_titles_from_comment(comment):\n",
    "    \"\"\" \n",
    "    Extracts all book titles found in a comment body\n",
    "    See the pipeline steps mentioned in the cell above.\n",
    "    \"\"\"\n",
    "    titles = set()\n",
    "    # avoid dealing with all the special markup characters\n",
    "    text = markdown_to_text(comment.body)\n",
    "    # for each sentence, extract the title(s)\n",
    "    for sentence in sent_tokenize(text):\n",
    "        \n",
    "        titles_found = _match_titles(sentence)\n",
    "        if DEBUG and not titles_found:\n",
    "            print(f'sentence: {sentence}')\n",
    "            print('titles found:')\n",
    "            print(\"\\n\".join(titles_found))\n",
    "            print('-' * 80)\n",
    "        titles.update(titles_found)\n",
    "    return titles\n",
    "\n",
    "\n",
    "def bulk_extract(comments):\n",
    "    \"\"\" \"\"\"\n",
    "    all_titles = set()\n",
    "    for comment in comments:\n",
    "        titles = extract_titles_from_comment(comment)\n",
    "        all_titles.update(titles)\n",
    "    return all_titles\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A Short Stay in Hell by Steven Peck',\n",
       " 'All the Ugly and Wonderful Things by Bryn Greenwood This',\n",
       " 'Also Lull by Kelly Link',\n",
       " 'And The Second Kind Of Loneliness',\n",
       " 'Beyond Black by Hilary Mantel',\n",
       " 'Bird Box by Josh Malerman',\n",
       " 'Blasted by Sarah Kane',\n",
       " 'Blood Meridian by Cormac McCarthy',\n",
       " 'Caring Is Creepy by David Zimmerman',\n",
       " 'Clive Barker Books of Blood',\n",
       " 'Coin Locker Babies by Murakami',\n",
       " 'Cows by Matthew Stokoe',\n",
       " 'Eleven Twenty Three by Jason Hornsby Preta Realm by J Thorn A',\n",
       " 'False Memory by Dean Koontz',\n",
       " 'Fish in Exile by Vi Khi Nao',\n",
       " 'Flowers In The Attic VC Andrews',\n",
       " 'From George R R Martin',\n",
       " 'Haunted by Chuck Palahniuk',\n",
       " 'Her Fearful Symmetry by Audrey Niffenegger',\n",
       " 'I Thinking of Ending Things by Iain Reid',\n",
       " 'In the Miso Soup by Ryu Murakami',\n",
       " 'Like A Song For Lya',\n",
       " 'Liminal States by Zach Parsons',\n",
       " 'Lost Souls by Poppy Z Bright',\n",
       " 'Lunar Park Bret Easton Ellis',\n",
       " 'No One Gets Out Alive by Adam Nevill I',\n",
       " 'North American Lake Monsters',\n",
       " 'Off Season by Jack Ketchum',\n",
       " 'Perfume The Story of a Murderer',\n",
       " 'Poppy Brite Lost Souls',\n",
       " 'Pygmy by Chuck Palahniuk',\n",
       " 'Slade House by David Mitchell',\n",
       " 'Song of Kali by Dan Simmons',\n",
       " 'Stay Awake by Dan Chaon and The Museum of Moses Tales of Mystery and Suspense by Joyce Carol Oates',\n",
       " 'The Bunker Diary by Kevin Brooks',\n",
       " 'The Cipher by Kathe Koja',\n",
       " 'The Collector by John Fowles It',\n",
       " 'The Conspiracy Against The Human Race by Thomas Ligotti',\n",
       " 'The Devil of Nanking by Mo Hayder',\n",
       " 'The Dinner Herman Koch',\n",
       " 'The Heart is Deceitful Above All Things and Sarah',\n",
       " 'The Laws of Nature by Ashley Franz Holzmann',\n",
       " 'The Music of Chance by Paul Auster',\n",
       " 'The Mysterious Stranger Mark Twain',\n",
       " 'The Painted Bird by Kozinski',\n",
       " 'The Room by Hubert Selby Pleasseeee',\n",
       " 'The Story of the Eye by Georges Bataille',\n",
       " 'The Stuff of Nightmares by Malorie Blackman',\n",
       " 'The Surgeon Tess Gerritsen',\n",
       " 'The Tsar of Love and Techno by Anthony Marra',\n",
       " 'The Vegetarian by Han Kang',\n",
       " 'The Wasp Factory by Iain Banks',\n",
       " 'The Yellow Wallpaper by Charlotte Perkins Gilman',\n",
       " 'Till We Have Faces',\n",
       " 'Twenty Days of Turin The Water Knife',\n",
       " 'Uzumaki by Junji Ito',\n",
       " 'Wine Dark Sea by Robert Aickman',\n",
       " 'Zombie by Joyce Carol Oats'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bulk_extract(comments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
